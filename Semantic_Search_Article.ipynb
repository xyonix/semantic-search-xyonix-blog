{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a9dba-13bd-4fd2-b3b1-1ff3ff963d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This python notebook is a companion to the semantic search article here <insert url after publishing>\n",
    "# Prerequisites:\n",
    "# $ pip install -U sentence-transformers\n",
    "# $ pip install -U opensearch-py\n",
    "# Install opensearch, docker install is easy: https://opensearch.org/docs/latest/install-and-configure/install-opensearch/index/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde0748-be0f-4d03-9bc2-3ba1254b156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute embeddings for test data\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n",
    "\n",
    "descriptions = ['car', 'bus', 'house', 'cat', 'dog']\n",
    "embeddings = [model.encode(description) for description in descriptions]\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19637504-2c0c-4cfd-8d9c-96ba2db07b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute embeddings (again) parallelized ... use this if you have a large number of embeddings to compute\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from time import time\n",
    "\n",
    "# if your SentenceTransformer device is 'cuda' or 'mps' you should count GPU cores in the next line instead of CPU cores\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "with concurrent.futures.ThreadPoolExecutor(num_processes) as pool:\n",
    "    futures = [pool.submit(model.encode, item) for item in descriptions]  \n",
    "    embeddings = [f.result() for f in futures]\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1372a02-ee9a-402e-94ff-7a032213da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "\n",
    "# Connect to OpenSearch\n",
    "# Note your configuration may be different depending on how you set it up\n",
    "# We ran it via docker locally with -e \"plugins.security.disabled=true\"\n",
    "# Don't forget to add your OpenSearch password below\n",
    "\n",
    "host = 'localhost'\n",
    "port = 9200\n",
    "auth = ('admin', '<your opensearch password>')\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    use_ssl = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842cecd3-6e5f-43e6-92dc-703e40aa1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate index\n",
    "index_name = \"semantic_index\"\n",
    "\n",
    "# delete index if it already exists\n",
    "client.indices.delete(index=index_name)\n",
    "\n",
    "# index schema\n",
    "mapping = \\\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"index\": {\n",
    "      \"knn\": True,\n",
    "      \"knn.algo_param.ef_search\": 100\n",
    "    }\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "        \"description_emb\": {\n",
    "          \"type\": \"knn_vector\",\n",
    "          \"dimension\": 384,\n",
    "          \"method\": {\n",
    "            \"name\": \"hnsw\",\n",
    "            \"space_type\": \"l2\",\n",
    "            \"engine\": \"nmslib\",\n",
    "            \"parameters\": {\n",
    "              \"ef_construction\": 128,\n",
    "              \"m\": 24\n",
    "            }\n",
    "          }\n",
    "      },\n",
    "      \"media_url\": {\n",
    "        \"type\": \"binary\"\n",
    "      },\n",
    "      \"description\": {\n",
    "        \"type\": \"text\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# create index\n",
    "client.indices.create(index=index_name, body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bea59-cc67-4d07-aef8-880cad2de61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index documents\n",
    "# Note that for large data sets bulk indexing will be much faster as documented here: \n",
    "# https://opensearch.org/docs/latest/clients/python-low-level/\n",
    "\n",
    "for i in range(len(descriptions)):\n",
    "    document = {\n",
    "        'description': descriptions[i],\n",
    "        'media_url': 'http://this.would/point/to/the/media.jpg',\n",
    "        'description_emb': embeddings[i]\n",
    "    }\n",
    "    \n",
    "    client.index(index=index_name, body=document)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2284e6-a699-453d-8b0b-52d74a33115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate embedding for query\n",
    "user_query = \"motorcycle\"\n",
    "user_query_emb = model.encode(user_query)\n",
    "\n",
    "# construct opensearch query and submit\n",
    "desired_results = 2\n",
    "opensearch_query = { \"size\": desired_results, \"query\": {\"knn\": { \"description_emb\": {\"vector\": user_query_emb, \"k\": desired_results } } } }\n",
    "\n",
    "from time import sleep\n",
    "sleep(1) # give OpenSearch a second to catch up if you're running the entire notebook top to bottom\n",
    "results = client.search(index=index_name, body=opensearch_query)\n",
    "\n",
    "for result in results['hits']['hits']:\n",
    "    print(result['_source']['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021ddf7-584b-4629-90e1-5cad2d02b96b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newlibs",
   "language": "python",
   "name": "newlibs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
